{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Check current Python version\n",
        "!python3 --version\n",
        "\n",
        "# Install Python 3.10 and required dependencies\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10 python3.10-dev python3.10-distutils -y\n",
        "\n",
        "# Point Colab to use Python 3.10\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
        "\n",
        "# Reinstall pip for Python 3.10\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | sudo python3.10\n",
        "\n",
        "# Verify Python version\n",
        "!python3 --version\n",
        "!pip --version\n",
        "\n",
        "# Restart the runtime so changes take effect\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcCn7UuSe0bk",
        "outputId": "4e77c7fb-a709-4ca7-f645-ea6c0bc1b88e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.10-distutils'\n",
            "python3-distutils is already the newest version (3.10.8-1~22.04).\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.11).\n",
            "python3.10-dev is already the newest version (3.10.12-1~22.04.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "Traceback (most recent call last):\n",
            "  File \"<stdin>\", line 27368, in <module>\n",
            "  File \"<stdin>\", line 137, in main\n",
            "  File \"<stdin>\", line 113, in bootstrap\n",
            "  File \"<stdin>\", line 94, in monkeypatch_for_cert\n",
            "  File \"/tmp/tmp5hvoeqba/pip.zip/pip/_internal/commands/__init__.py\", line 11, in <module>\n",
            "  File \"/tmp/tmp5hvoeqba/pip.zip/pip/_internal/cli/base_command.py\", line 17, in <module>\n",
            "  File \"/tmp/tmp5hvoeqba/pip.zip/pip/_internal/cli/cmdoptions.py\", line 25, in <module>\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 945, in _find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1439, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1411, in _get_spec\n",
            "  File \"<frozen zipimport>\", line 170, in find_spec\n",
            "  File \"<frozen importlib._bootstrap>\", line 431, in spec_from_loader\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 741, in spec_from_file_location\n",
            "  File \"<frozen zipimport>\", line 229, in get_filename\n",
            "  File \"<frozen zipimport>\", line 767, in _get_module_code\n",
            "  File \"<frozen zipimport>\", line 696, in _compile_source\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Python 3.12.12\n",
            "pip 25.3 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YytyBTZaej1s",
        "outputId": "74e68f72-02fa-4b18-c19e-7f4329b29348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SnappFood-Sentiment-Analysis'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 46 (delta 12), reused 40 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (46/46), 2.94 MiB | 7.71 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mahanzavari/SnappFood-Sentiment-Analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/SnappFood-Sentiment-Analysis/* /content/"
      ],
      "metadata": {
        "id": "nd6R0P-ce8h1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3.10 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI0p1-_Zf-nI",
        "outputId": "f9938302-e294-4a7e-f5fc-e3039a473ee0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting hazm (from -r requirements.txt (line 2))\n",
            "  Downloading hazm-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting transformers (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting pandas (from -r requirements.txt (line 4))\n",
            "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting scikit-learn (from -r requirements.txt (line 5))\n",
            "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting gunicorn (from -r requirements.txt (line 6))\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting pyYAML (from -r requirements.txt (line 7))\n",
            "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tqdm (from -r requirements.txt (line 8))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting filelock (from torch->-r requirements.txt (line 1))\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx>=2.5.1 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=0.8.5 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.0 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm->-r requirements.txt (line 2))\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting flashtext<3.0,>=2.7 (from hazm->-r requirements.txt (line 2))\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gensim<5.0.0,>=4.3.1 (from hazm->-r requirements.txt (line 2))\n",
            "  Downloading gensim-4.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting nltk<4.0.0,>=3.8.1 (from hazm->-r requirements.txt (line 2))\n",
            "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting numpy==1.24.3 (from hazm->-r requirements.txt (line 2))\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting python-crfsuite<0.10.0,>=0.9.9 (from hazm->-r requirements.txt (line 2))\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn->-r requirements.txt (line 5))\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 5))\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 5))\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel<0.10.0,>=0.9.2->hazm->-r requirements.txt (line 2))\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm->-r requirements.txt (line 2)) (80.9.0)\n",
            "Collecting smart_open>=1.8.1 (from gensim<5.0.0,>=4.3.1->hazm->-r requirements.txt (line 2))\n",
            "  Downloading smart_open-7.4.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting click (from nltk<4.0.0,>=3.8.1->hazm->-r requirements.txt (line 2))\n",
            "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->hazm->-r requirements.txt (line 2))\n",
            "  Downloading regex-2025.10.23-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->-r requirements.txt (line 3))\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting packaging>=20.0 (from transformers->-r requirements.txt (line 3))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting requests (from transformers->-r requirements.txt (line 3))\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers->-r requirements.txt (line 3))\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 3))\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->-r requirements.txt (line 4))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 4))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 4))\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.16.0)\n",
            "Collecting wrapt (from smart_open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm->-r requirements.txt (line 2))\n",
            "  Downloading wrapt-2.0.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->-r requirements.txt (line 1))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.0.1)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->transformers->-r requirements.txt (line 3))\n",
            "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers->-r requirements.txt (line 3))\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers->-r requirements.txt (line 3))\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers->-r requirements.txt (line 3))\n",
            "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading torch-2.9.0-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m  \u001b[33m0:00:27\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m  \u001b[33m0:00:18\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m  \u001b[33m0:00:13\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m  \u001b[33m0:00:19\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.5.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading hazm-0.10.0-py3-none-any.whl (892 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m177.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m146.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.4.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.6/27.6 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m157.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading regex-2025.10.23-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (791 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m791.5/791.5 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
            "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.4.1-py3-none-any.whl (63 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m156.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
            "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
            "Downloading wrapt-2.0.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (113 kB)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9372 sha256=86f1218be48e3c5f714fdebe9e6c7570e7f3d27fd1cc582a834c7bdf2f69377a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built flashtext\n",
            "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, flashtext, wrapt, urllib3, tzdata, typing-extensions, triton, tqdm, threadpoolctl, sympy, safetensors, regex, pyYAML, python-dateutil, python-crfsuite, pybind11, packaging, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, joblib, jinja2, idna, hf-xet, fsspec, filelock, click, charset_normalizer, certifi, smart_open, scipy, requests, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nltk, gunicorn, fasttext-wheel, scikit-learn, nvidia-cusolver-cu12, huggingface-hub, gensim, torch, tokenizers, hazm, transformers\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58/58\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.10.5 charset_normalizer-3.4.4 click-8.3.0 fasttext-wheel-0.9.2 filelock-3.20.0 flashtext-2.7 fsspec-2025.10.0 gensim-4.4.0 gunicorn-23.0.0 hazm-0.10.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 networkx-3.4.2 nltk-3.9.2 numpy-1.24.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 packaging-25.0 pandas-2.3.3 pyYAML-6.0.3 pybind11-3.0.1 python-crfsuite-0.9.11 python-dateutil-2.9.0.post0 pytz-2025.2 regex-2025.10.23 requests-2.32.5 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.15.3 smart_open-7.4.1 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 triton-3.5.0 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0 wrapt-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAVgG_RSgGXW",
        "outputId": "713559f3-74ec-4a87-cb71-ca9fb2b834c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and cleaned. Shape: (66260, 2)\n",
            "applying, preprocessings...\n",
            "Preprocessing Comments: 100% 66260/66260 [00:17<00:00, 3787.41it/s]\n",
            "spliting the dataset..\n",
            "  dataset Splitted successfully\n",
            "Loading Tokernizer...\n",
            "tokenizing dataset...\n",
            "Tokenization complete.\n",
            "Loading DataLoaders...\n",
            "  DataLoaders Loaded successfully\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Starting training...\n",
            "Epoch 1 [Train]: 100% 1450/1450 [08:23<00:00,  2.88it/s]\n",
            "Epoch 1 [Val]: 100% 311/311 [00:35<00:00,  8.82it/s]\n",
            "Epoch 1: Train Loss=0.3287, Val Loss=0.3218\n",
            "Model saved to /content/models/parsbert-sentiment-v1\n",
            "Epoch 2 [Train]: 100% 1450/1450 [08:29<00:00,  2.85it/s]\n",
            "Epoch 2 [Val]: 100% 311/311 [00:35<00:00,  8.82it/s]\n",
            "Epoch 2: Train Loss=0.2665, Val Loss=0.3052\n",
            "Model saved to /content/models/parsbert-sentiment-v1\n",
            "Epoch 3 [Train]: 100% 1450/1450 [08:29<00:00,  2.85it/s]\n",
            "Epoch 3 [Val]: 100% 311/311 [00:35<00:00,  8.85it/s]\n",
            "Epoch 3: Train Loss=0.2094, Val Loss=0.3532\n",
            "Epoch 4 [Train]: 100% 1450/1450 [08:28<00:00,  2.85it/s]\n",
            "Epoch 4 [Val]: 100% 311/311 [00:35<00:00,  8.79it/s]\n",
            "Epoch 4: Train Loss=0.1504, Val Loss=0.4120\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.py\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import sys\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "matplotlib.use('Agg') # Use the 'Agg' backend for non-interactive plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# --- Setup: Ensure our src modules can be imported ---\n",
        "# This is necessary if your notebook is in the root directory\n",
        "if 'src' not in sys.path:\n",
        "    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('.'), 'src')))\n",
        "\n",
        "from data_preprocessing import load_config, load_and_clean_data, text_preprocessor\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. LOAD CONFIGURATION AND DATA\n",
        "# ==============================================================================\n",
        "print(\"--- Loading Configuration and Data ---\")\n",
        "config = load_config()\n",
        "df = load_and_clean_data(config)\n",
        "\n",
        "# Apply the same text preprocessing\n",
        "tqdm.pandas(desc=\"Preprocessing Test Comments\")\n",
        "df['comment'] = df['comment'].progress_apply(text_preprocessor)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. RE-CREATE THE EXACT SAME TEST SET\n",
        "# This step is CRITICAL for a valid evaluation.\n",
        "# We use the same random_state and stratify settings as in train.py\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Re-creating the Test Set for Evaluation ---\")\n",
        "X = df['comment']\n",
        "y = df['label_id']\n",
        "\n",
        "# First split to separate out the training set\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=(config['train']['test_size'] + config['train']['val_size']), random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split to get the validation and test sets\n",
        "val_size_adjusted = config['train']['val_size'] / (config['train']['test_size'] + config['train']['val_size'])\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=(1-val_size_adjusted), random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Evaluation will be performed on {len(X_test)} test samples.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. LOAD THE FINE-TUNED MODEL AND TOKENIZER\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Loading Fine-Tuned Model and Tokenizer ---\")\n",
        "model_path = config['model']['save_path']\n",
        "if not os.path.exists(model_path):\n",
        "    raise FileNotFoundError(f\"Model not found at {model_path}. Please run src/train.py first.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
        "print(f\"Model loaded from '{model_path}' and moved to {device}.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. PREPARE THE TEST DATA FOR INFERENCE\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Preparing Test DataLoader ---\")\n",
        "# Tokenize the test data\n",
        "test_encodings = tokenizer(\n",
        "    X_test.tolist(),\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=config['train']['max_length'],\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Create Dataset and DataLoader\n",
        "test_dataset = TensorDataset(\n",
        "    test_encodings['input_ids'],\n",
        "    test_encodings['attention_mask'],\n",
        "    torch.tensor(y_test.values)\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['train']['batch_size'])\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. RUN EVALUATION\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Evaluating Model Performance on the Test Set ---\")\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Use torch.no_grad() for inference to save memory and speed up computation\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        all_preds.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. DISPLAY RESULTS\n",
        "# ==============================================================================\n",
        "print(\"\\n\\n--- Evaluation Results ---\")\n",
        "\n",
        "# Print Classification Report\n",
        "print(\"Classification Report:\")\n",
        "# The labels correspond to 0: HAPPY, 1: SAD\n",
        "print(classification_report(all_labels, all_preds, target_names=['HAPPY', 'SAD']))\n",
        "\n",
        "# Display Confusion Matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['HAPPY', 'SAD'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp.plot(ax=ax, cmap='Blues')\n",
        "plt.show() # Keep plt.show() if you want to display the plot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppqpom-nuZSV",
        "outputId": "e7627df5-46c9-41e5-c18e-0d04db2ef6f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3.10 install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZOMwXlZ9ejg",
        "outputId": "c9d5152a-ffcd-45db-d7c7-7b92a82377e0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (12.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "!python3.10 test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHQYvIyE9GrY",
        "outputId": "4cdee36e-ecb6-4463-c85d-2640e2152a3d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Configuration and Data ---\n",
            "Data loaded and cleaned. Shape: (66260, 2)\n",
            "Preprocessing Test Comments: 100% 66260/66260 [00:17<00:00, 3808.21it/s]\n",
            "\n",
            "--- Re-creating the Test Set for Evaluation ---\n",
            "Evaluation will be performed on 9939 test samples.\n",
            "\n",
            "--- Loading Fine-Tuned Model and Tokenizer ---\n",
            "Model loaded from '/content/models/parsbert-sentiment-v1' and moved to cuda.\n",
            "\n",
            "--- Preparing Test DataLoader ---\n",
            "\n",
            "--- Evaluating Model Performance on the Test Set ---\n",
            "Predicting: 100% 311/311 [00:30<00:00, 10.13it/s]\n",
            "\n",
            "\n",
            "--- Evaluation Results ---\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       HAPPY       0.92      0.82      0.87      5057\n",
            "         SAD       0.83      0.93      0.88      4882\n",
            "\n",
            "    accuracy                           0.87      9939\n",
            "   macro avg       0.88      0.87      0.87      9939\n",
            "weighted avg       0.88      0.87      0.87      9939\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRsAi8bB9bSi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}